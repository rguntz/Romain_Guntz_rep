{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# this jupyter notebook is going to test the openai api to test things. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_key = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple test to check if the openAI api works : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, in a sparkling forest filled with twinkling fireflies and soft, hush-hush breezes, there lived a gentle unicorn named Lila. Lila’s coat shimmered like moonlight, and her horn glowed with warm, golden magic.\n",
      "\n",
      "Every night, before the other forest creatures went to bed, Lila would use her magic to create a beautiful gentle light that lit up the darkest corners of the woods. Little bunnies snuggled close, the owls blinked sleepily, and the deer lay their heads on patches of moss, feeling safe and cozy.\n",
      "\n",
      "One evening, as the stars began to twinkle above, Lila heard a tiny sob. Following the sound, she found a baby squirrel named Pip, who had lost his way home. Lila smiled softly and bent her head low. “Climb onto my back, Pip,” she whispered.\n",
      "\n",
      "With Pip nestled between her silvery mane, Lila trotted gently through the trees, her horn lighting the way. They passed sleepy foxes, giggling fairies, and a wise old owl. Soon, they reached Pip’s cozy nest high in an ancient oak tree.\n",
      "\n",
      "“Thank you, Lila,” Pip yawned, already drifting to sleep. Lila nuzzled him goodnight, then tiptoed away, her heart full of happiness.\n",
      "\n",
      "And every night after, all the creatures knew that as long as Lila was near, dreams would be bright and the forest would always feel like home.\n",
      "\n",
      "Goodnight, sweet dreamer.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=API_key)\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4.1\",\n",
    "    input=\"Write a short bedtime story about a unicorn.\"\n",
    ")\n",
    "\n",
    "print(response.output_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the moment, we only output a german sentence done using 3 words : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Der Hund möchte bei kaltem Wetter nicht auf der Straße gehen.\n"
     ]
    }
   ],
   "source": [
    "words = [\"Hund\", \"Straße\", \"gehen\", \"kalt\"]\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Create one natural and grammatically correct German sentence that uses exactly these four words: \n",
    "\"{words[0]}\", \"{words[1]}\", \"{words[2]}\", \"{words[3]}\".\n",
    "\n",
    "Respond only with the sentence.\n",
    "\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4.1\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are an assistant that generates German sentences.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will output 2 sentences : the german sentence and the translation in english using the same output of the model : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GERMAN: Der Hund möchte bei kaltem Wetter nicht auf der Straße gehen.\n",
      "ENGLISH: The dog does not want to walk on the street in cold weather.\n",
      "German: Der Hund möchte bei kaltem Wetter nicht auf der Straße gehen.\n",
      "English: The dog does not want to walk on the street in cold weather.\n"
     ]
    }
   ],
   "source": [
    "words = [\"Hund\", \"Straße\", \"gehen\", \"kalt\"]\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Create one natural and grammatically correct German sentence that uses exactly these four words: \n",
    "\"{words[0]}\", \"{words[1]}\", \"{words[2]}\", \"{words[3]}\".\n",
    "\n",
    "After that, provide the English translation of this sentence.\n",
    "\n",
    "Format your response like this:\n",
    "\n",
    "GERMAN: <German sentence>\n",
    "ENGLISH: <English translation>\n",
    "\n",
    "Respond only with this format, nothing else.\n",
    "\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4.1\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are an assistant that generates German sentences and their English translations.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ],\n",
    "    temperature=0.7  # Higher = more creative/random, range 0–2\n",
    ")\n",
    "\n",
    "\n",
    "output = response.choices[0].message.content\n",
    "print(output)\n",
    "\n",
    "# Split easily in Python\n",
    "lines = output.splitlines()\n",
    "german_sentence = lines[0].replace(\"GERMAN: \", \"\").strip()\n",
    "english_sentence = lines[1].replace(\"ENGLISH: \", \"\").strip()\n",
    "\n",
    "print(\"German:\", german_sentence)\n",
    "print(\"English:\", english_sentence)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to find the german dictionary online and the frequency of words. I have found a dictionary in txt format with the words and their corresponding frequency : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first need to do some modifications because the first words of the list are actually symbols so we are going to remove them : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved JSON with 36137 words to data/deu_news_10K_words.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Input and output files\n",
    "input_file = \"data/deu_news_2024_10K/deu_news_2024_10K-words.txt\"\n",
    "output_file = \"data/deu_news_10K_words.json\"\n",
    "\n",
    "# Step 1: Read the file\n",
    "words_list = []\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        parts = line.strip().split(\"\\t\")\n",
    "        if len(parts) == 3:\n",
    "            id_, word, freq = parts\n",
    "            id_ = int(id_)\n",
    "            freq = int(freq)\n",
    "            # Step 2: Keep only words with ID > 86\n",
    "            if id_ > 86:\n",
    "                words_list.append({\"id\": id_, \"word\": word, \"frequency\": freq})\n",
    "\n",
    "# Step 3: Reorder IDs starting from 1\n",
    "for new_id, entry in enumerate(words_list, start=1):\n",
    "    entry[\"id\"] = new_id\n",
    "\n",
    "# Step 4: Save to JSON\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(words_list, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"Saved JSON with {len(words_list)} words to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the path of the json dataset file : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_JSON = \"/Users/administrateur/Desktop/ETH_master/BMW/Projects/German_learner/data/deu_news_10K_words.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to create a new json file but this time have the assigned probability of a sampling a word. This probability is going to be saved into a new key. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved JSON with probabilities to data/deu_news_10K_words_with_prob.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Input and output files\n",
    "input_file = PATH_JSON\n",
    "output_file = \"data/deu_news_10K_words_with_prob.json\"\n",
    "\n",
    "# Step 1: Load the JSON file\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    words_list = json.load(f)\n",
    "\n",
    "# Step 2: Compute total frequency\n",
    "total_frequency = sum(entry[\"frequency\"] for entry in words_list)\n",
    "\n",
    "# Step 3: Assign probability to each word\n",
    "for entry in words_list:\n",
    "    entry[\"probability\"] = entry[\"frequency\"] / total_frequency\n",
    "\n",
    "# Step 4: Save to new JSON file\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(words_list, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"Saved JSON with probabilities to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the new path of the json file : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_JSON_PROBA = \"/Users/administrateur/Desktop/ETH_master/BMW/Projects/German_learner/data/deu_news_10K_words_with_prob.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "def sample_words(json_file, n):\n",
    "    \"\"\"\n",
    "    Sample n words from a German word frequency JSON file according to their probability.\n",
    "\n",
    "    Args:\n",
    "        json_file (str): Path to the JSON file with 'word' and 'probability' fields.\n",
    "        n (int): Number of words to sample.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of sampled words.\n",
    "    \"\"\"\n",
    "    # Load JSON data\n",
    "    with open(json_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        words_list = json.load(f)\n",
    "\n",
    "    # Extract words and probabilities\n",
    "    words = [entry[\"word\"] for entry in words_list]\n",
    "    probabilities = [entry[\"probability\"] for entry in words_list]\n",
    "\n",
    "    # Sample n words according to probabilities (with replacement)\n",
    "    sampled_words = random.choices(words, weights=probabilities, k=n)\n",
    "\n",
    "    return sampled_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will clean the words that are not \"words\" because some of them are numbers (it was internet scrapped so that's why is not perfect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned JSON with 35256 words to data/deu_news_10K_words_clean.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Input and output files\n",
    "input_file = PATH_JSON_PROBA\n",
    "output_file = \"data/deu_news_10K_words_clean.json\"\n",
    "\n",
    "# Step 1: Load the JSON file\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    words_list = json.load(f)\n",
    "\n",
    "# Step 2: Filter out entries where the word is a number\n",
    "# Keep only words that contain at least one alphabetic character\n",
    "cleaned_list = [entry for entry in words_list if any(c.isalpha() for c in entry[\"word\"])]\n",
    "\n",
    "# Step 3: Reorder IDs starting from 1\n",
    "for new_id, entry in enumerate(cleaned_list, start=1):\n",
    "    entry[\"id\"] = new_id\n",
    "\n",
    "# Step 4: Save the cleaned JSON file\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(cleaned_list, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"Saved cleaned JSON with {len(cleaned_list)} words to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the new path : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_JSON_PROBA_CLEAN = \"/Users/administrateur/Desktop/ETH_master/BMW/Projects/German_learner/data/deu_news_10K_words_clean.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we do the functiont that takes as input n words and generate a sentence using chatgpt api : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence(client, words, temperature=0.7):\n",
    "    \"\"\"\n",
    "    Generate a German sentence using the given words and its English translation.\n",
    "\n",
    "    Args:\n",
    "        client: OpenAI client instance.\n",
    "        words (list of str): List of words to include in the sentence.\n",
    "        temperature (float): Creativity/randomness of the model (default 0.7).\n",
    "\n",
    "    Returns:\n",
    "        tuple: (german_sentence, english_sentence)\n",
    "    \"\"\"\n",
    "    if not words or len(words) == 0:\n",
    "        raise ValueError(\"The words list must contain at least one word.\")\n",
    "\n",
    "    # Build the prompt dynamically\n",
    "    word_list_str = ', '.join(f'\"{w}\"' for w in words)\n",
    "    prompt = f\"\"\"\n",
    "Create one natural and grammatically correct German sentence that uses exactly these words: \n",
    "{word_list_str}.\n",
    "\n",
    "After that, provide the English translation of this sentence.\n",
    "\n",
    "Format your response like this:\n",
    "\n",
    "GERMAN: <German sentence>\n",
    "ENGLISH: <English translation>\n",
    "\n",
    "Respond only with this format, nothing else.\n",
    "\"\"\"\n",
    "\n",
    "    # Call the OpenAI API\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4.1\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an assistant that generates German sentences and their English translations.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=temperature\n",
    "    )\n",
    "\n",
    "    # Extract the output\n",
    "    output = response.choices[0].message.content.strip()\n",
    "    lines = output.splitlines()\n",
    "\n",
    "    # Parse German and English sentences\n",
    "    german_sentence = None\n",
    "    english_sentence = None\n",
    "    for line in lines:\n",
    "        if line.startswith(\"GERMAN:\"):\n",
    "            german_sentence = line.replace(\"GERMAN: \", \"\").strip()\n",
    "        elif line.startswith(\"ENGLISH:\"):\n",
    "            english_sentence = line.replace(\"ENGLISH: \", \"\").strip()\n",
    "\n",
    "    if not german_sentence or not english_sentence:\n",
    "        raise ValueError(\"Failed to parse the model output correctly.\")\n",
    "\n",
    "    return german_sentence, english_sentence\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "German: Der Hund will bei diesem kalten Wetter nicht auf die Straße gehen.\n",
      "English: The dog doesn't want to go out on the street in this cold weather.\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "words = [\"Hund\", \"Straße\", \"gehen\", \"kalt\"]\n",
    "german, english = generate_sentence(client, words)\n",
    "print(\"German:\", german)\n",
    "print(\"English:\", english)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text to voice in german "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: piper-tts in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.3.0)\n",
      "Requirement already satisfied: onnxruntime<2,>=1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from piper-tts) (1.23.2)\n",
      "Requirement already satisfied: coloredlogs in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from onnxruntime<2,>=1->piper-tts) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from onnxruntime<2,>=1->piper-tts) (24.3.25)\n",
      "Requirement already satisfied: numpy>=1.21.6 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from onnxruntime<2,>=1->piper-tts) (2.2.6)\n",
      "Requirement already satisfied: packaging in /Users/administrateur/Library/Python/3.12/lib/python/site-packages (from onnxruntime<2,>=1->piper-tts) (24.1)\n",
      "Requirement already satisfied: protobuf in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from onnxruntime<2,>=1->piper-tts) (4.25.4)\n",
      "Requirement already satisfied: sympy in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from onnxruntime<2,>=1->piper-tts) (1.13.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from coloredlogs->onnxruntime<2,>=1->piper-tts) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sympy->onnxruntime<2,>=1->piper-tts) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install piper-tts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1707834939.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[8], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    from piper-tts import infer\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from piper_tts import infer\n",
    "\n",
    "# Path to the downloaded model\n",
    "model_path = \"/Users/administrateur/piper_voices/de_DE-thorsten-medium.onnx\"\n",
    "\n",
    "# Text you want to synthesize\n",
    "text = \"Guten Morgen, wie geht es dir?\"\n",
    "\n",
    "# Path to save the output WAV\n",
    "output_path = \"/Users/administrateur/Desktop/ETH_master/BMW/Projects/German_learner/data/voices/test.wav\"\n",
    "\n",
    "# Run synthesis\n",
    "infer(model_path=model_path, text=text, output_path=output_path)\n",
    "\n",
    "print(f\"WAV file saved at: {output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
